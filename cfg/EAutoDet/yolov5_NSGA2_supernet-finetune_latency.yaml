search_root_path: &search_root_path runs/coco_EAutoDet-s_nogumbelOp/NSGA2_supernet-finetune_latency/

model: &model cfg/model/EAutoDet-s_nogumbelOp.yaml

search_space: &search_space 
  model: !cross_ref [*model]

eval_cfg:
  epoch: &epoch 2
  root_path: &root_path !join [*search_root_path, eval_sample/]
  accumulate_gradient: &acc_grad 1
  
  data: &data cfg/dataset/coco_yolo.yaml
  pretrain: &pretrain runs/coco_EAutoDet-s_nogumbelOp/ckpt/best.pt 
  criterion: &criterion 
    submodule_name: src.criterions.YOLOv5Loss
    args:
      hyp:
        box: 0.05  # box loss gain
        cls: 0.5  # cls loss gain
        cls_pw: 1.0  # cls BCELoss positive_weight
        obj: 1.0  # obj loss gain (scale with pixels)
        obj_pw: 1.0  # obj BCELoss positive_weight
        iou_t: 0.20  # IoU training threshold
        anchor_t: 4.0  # anchor-multiple threshold
        fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)
      img_size: !cross_ref [!join [*data, ':input_size']]
      strides: !cross_ref [!join [*model, ':strides']]
      anchors: !cross_ref [!join [*model, ':anchors']]
      iou_loss_ratio: 1.0
      autobalance: False
  
  train_hyp: &hyp
    lr0: &lr0 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)
    lrf: &lrf 0.2  # final OneCycleLR learning rate (lr0 * lrf)
    momentum: &momentum 0.937  # SGD momentum/Adam beta1
    weight_decay: &wd !expr ['0.0005/64*', !cross_ref [!join [*data, ":batch_size"]]]  # optimizer weight decay 5e-4 * bs / 64
    warmup_epochs: 3.0  # warmup epochs (fractions ok)
    warmup_init_momentum: &warmup_init_momentum 0.8 
    warmup_bias_lr: &warmup_bias_lr 0.1  
  
  
  optimizer: &optimizer
    submodule_name: torch.optim.SGD
    args:
      params: [{'params': bn_parameters}, {'params': bias_parameters}, {'params': all_parameters, 'weight_decay': *wd}]
      lr: *lr0
      momentum: *momentum
      nesterov: True
  
  lr_scheduler: &scheduler
    submodule_name: torch.optim.lr_scheduler.LambdaLR
    args:
      optimizer: 
      lr_lambda: !get_module [src.scheduler.one_cycle, {'start': 1, 'end': *lrf, 'steps': *epoch}]
  
  hooks: &hooks
    opt_hook:
      submodule_name: OptHOOK
      args:
        priority: 0
        accumulate_gradient: *acc_grad
    
    lr_scheduler_hook:
      submodule_name: LrScheduleHOOK
      args: 
        priority: 5
        mode: epoch
    eval_hook:
      submodule_name: EvalCOCOmAPHOOK
      args: 
        anno_file: 'data/coco2017/annotations/instances_val2017.json'
        iou_thres: 0.6
        conf_thres: 0.001
        eval_by_cocotools: True
        priority: 10
    
    ddp_hook:
      submodule_name: DDPHOOK
      args:
        priority: 10
    
    log_hook:
      submodule_name: LogHOOK
      args:
        logger_name: TrainPip
        log_path: !join [*root_path, test.log]
        print_freq: 100
        only_master: True
        priority: 20
    
    ckpt_hook:
      submodule_name: CkptHOOK
      args:
        save_root: &ckpt_root !join [*root_path, ckpt/]
        pretrain: *pretrain
        load_strict: False
        only_master: True
        priority: 20

    warmup_hook:
      submodule_name: WarmupHOOK
      args:
        max_epoch: 3 
        max_iter: 1000
        warmup_init_lr: [0, *warmup_bias_lr, 0]
        warmup_init_momentum: *warmup_init_momentum
        priority: 0
        accumulate_gradient: *acc_grad
  
    ema_hook:
      submodule_name: EMAHOOK
      args:
        decay: 0.9999
        priority: 5
        accumulate_gradient: *acc_grad
  
  
  eval_engine: &eval_engine
    submodule_name: engines.NNEngine
    args:
      data: !cross_ref [*data]
      model: !cross_ref [*model]
      criterion: *criterion
      optimizer: *optimizer
      lr_scheduler: *scheduler
      hooks: *hooks
      amp: True
      amp_val: True
    run_args:
      epochs: *epoch
      max_iter: 500
  
  eval_engine2: &eval_engine2
    submodule_name: engines.EdgeDeviceEngine
    args:
      input_size: !cross_ref [!join [*data, ':input_size']]
      ckpt_root: *ckpt_root
      remote_onnx_path: /home/wangxiaoxing/model.onnx
      remote_cmd: "docker run -t -i --privileged -v /dev/bus/usb:/dev/bus/usb -v /home/wangxiaoxing:/home/wangxiaoxing rknn-toolkit2:ubuntu20.04-cp38 sh -c 'adb devices && cd /home/wangxiaoxing/rknn_model_zoo/examples/yolov7/python && python test_onnx.py --onnx_path {onnx_path} --target rk3588 --quant i8'"
      host: 202.120.39.51
      username: wangxiaoxing
      pkey: '~/.ssh/id_rsa'
      port: 30022
      eval_names: [neg-latency]

searcher: &searcher
  submodule_name: src.searcher.EvolutionAlgorithm
  args:
    num_epoch: 20
    num_survive: 10
    num_crossover: 10
    num_mutation: 15
    num_population: 30
    prob_mutation: 0.1

contractor: &contractor
  submodule_name: src.evaluater.Contractor
  args:
    eval_engines: [*eval_engine, *eval_engine2]
    num_workers: 1
#    log_dir: !join [*root_path, eval_worker/]

search_hooks: &search_hooks
  ckpt_hook:
    submodule_name: SearchCkptHOOK
    args:
      priority: 30
      save_root: !join [*search_root_path, search/]


engine:
  submodule_name: engines.SearchEngine
  args:
    search_space: *search_space
    searcher: *searcher
    contractor: *contractor
    hooks: *search_hooks





